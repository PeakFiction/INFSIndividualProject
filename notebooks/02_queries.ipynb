{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56005372-7cc8-4ca4-85e1-61ce292f7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postgres JDBC driver is loaded ✅\n"
     ]
    }
   ],
   "source": [
    "#Cell A\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "JAR = \"/home/jovyan/jars/postgresql-42.7.4.jar\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"yelp-queries\")\n",
    "    # make the driver & executors see the jar no matter what\n",
    "    .config(\"spark.jars\", JAR)\n",
    "    .config(\"spark.driver.extraClassPath\", JAR)\n",
    "    .config(\"spark.executor.extraClassPath\", JAR)\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"268435456\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"64\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# sanity: this should NOT raise\n",
    "spark._jvm.java.lang.Class.forName(\"org.postgresql.Driver\")\n",
    "print(\"Postgres JDBC driver is loaded ✅\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2965e34c-944c-4b74-9588-820b5a779c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 397\n",
      "q2 257\n",
      "q3 10193\n",
      "q4 485\n"
     ]
    }
   ],
   "source": [
    "q1 = spark.read.parquet(\"/data/parquet/_tmp_q1\")\n",
    "q2 = spark.read.parquet(\"/data/parquet/_tmp_q2\")\n",
    "q3 = spark.read.parquet(\"/data/parquet/_tmp_q3\")\n",
    "q4 = spark.read.parquet(\"/data/parquet/_tmp_q4\")\n",
    "\n",
    "for name, df in {\"q1\": q1, \"q2\": q2, \"q3\": q3, \"q4\": q4}.items():\n",
    "    print(name, df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe98e3e1-c5a7-42b9-abf3-de4ba453de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote q1..q4 to Postgres ✅\n"
     ]
    }
   ],
   "source": [
    "jdbc = {\n",
    "    \"url\": \"jdbc:postgresql://db:5432/yelp\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"batchsize\": \"5000\",\n",
    "}\n",
    "\n",
    "for name, df in {\"q1\": q1, \"q2\": q2, \"q3\": q3, \"q4\": q4}.items():\n",
    "    (df.write.format(\"jdbc\")\n",
    "       .options(**jdbc)\n",
    "       .option(\"dbtable\", f\"public.{name}\")\n",
    "       .mode(\"overwrite\")\n",
    "       .save())\n",
    "print(\"Wrote q1..q4 to Postgres ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afb8ef-d48a-4acb-8d7a-4239e1090b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cell B\n",
    "biz = spark.read.parquet(\"/data/parquet/business\")\n",
    "tip = spark.read.parquet(\"/data/parquet/tip\")\n",
    "rev = spark.read.json(\"/data/raw/yelp_academic_dataset_review.json\")\n",
    "usr = spark.read.json(\"/data/raw/yelp_academic_dataset_user.json\")\n",
    "chk = spark.read.json(\"/data/raw/yelp_academic_dataset_checkin.json\")\n",
    "\n",
    "for v in [\"business\",\"tip\",\"review\",\"yelp_user\",\"checkin_raw\"]:\n",
    "    try: spark.catalog.dropTempView(v)\n",
    "    except: pass\n",
    "\n",
    "biz.createOrReplaceTempView(\"business\")\n",
    "tip.createOrReplaceTempView(\"tip\")\n",
    "rev.createOrReplaceTempView(\"review\")\n",
    "usr.createOrReplaceTempView(\"yelp_user\")\n",
    "chk.createOrReplaceTempView(\"checkin_raw\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc0035-73f9-424f-8599-143d620bfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell C\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Row counts\n",
    "for t in [\"business\",\"review\",\"yelp_user\",\"checkin_raw\",\"tip\"]:\n",
    "    spark.sql(f\"SELECT '{t}' AS tbl, COUNT(*) AS n FROM {t}\").show()\n",
    "\n",
    "# Categories presence\n",
    "cats = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN categories IS NULL OR length(categories)=0 THEN 1 ELSE 0 END) AS null_or_empty,\n",
    "  SUM(CASE WHEN categories IS NOT NULL AND length(categories)>0 THEN 1 ELSE 0 END) AS nonnull\n",
    "FROM business\n",
    "\"\"\")\n",
    "cats.show()\n",
    "assert cats.collect()[0][\"nonnull\"] > 0, \"business.categories are all null/empty\"\n",
    "\n",
    "# Checkin strings presence\n",
    "ckn = spark.sql(\"\"\"\n",
    "SELECT COUNT(*) AS nonempty_checkins\n",
    "FROM checkin_raw\n",
    "WHERE date IS NOT NULL AND length(date)>0\n",
    "\"\"\")\n",
    "ckn.show()\n",
    "assert ckn.collect()[0][\"nonempty_checkins\"] > 0, \"checkin_raw.date is empty\"\n",
    "\n",
    "# Review ↔ business join reachability\n",
    "jcnt = spark.sql(\"SELECT COUNT(*) AS joined FROM review r JOIN business b USING (business_id)\")\n",
    "jcnt.show()\n",
    "assert jcnt.collect()[0][\"joined\"] > 0, \"review × business join produced zero rows\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d521bca-ddb9-4aea-8603-7ee260b4fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell D\n",
    "rev_small = spark.table(\"review\").sample(False, 0.05, seed=42)\n",
    "rev_small.cache(); rev_small.count()\n",
    "rev_small.createOrReplaceTempView(\"review\")  # override with sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea3846-2993-423c-beec-da05995ea017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell E\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Business → category rows\n",
    "(spark.table(\"business\")\n",
    " .select(\"business_id\",\"name\",\"city\",\"state\",\"stars\",\"review_count\",\"is_open\",\"categories\")\n",
    " .withColumn(\"category\", F.explode(F.split(F.col(\"categories\"), \",\\\\s*\")))\n",
    " .withColumn(\"category\", F.trim(F.lower(F.col(\"category\"))))\n",
    " .dropna(subset=[\"category\"])\n",
    ").createOrReplaceTempView(\"business_category\")\n",
    "\n",
    "# Checkin counts per business\n",
    "(spark.table(\"checkin_raw\")\n",
    " .withColumn(\"ts\", F.explode(F.split(F.col(\"date\"), \",\\\\s*\")))\n",
    " .withColumn(\"checkin_ts\", F.to_timestamp(F.col(\"ts\")))\n",
    " .drop(\"ts\",\"date\")\n",
    " .groupBy(\"business_id\").count().withColumnRenamed(\"count\",\"checkin_events\")\n",
    ").createOrReplaceTempView(\"checkin_counts\")\n",
    "\n",
    "# User elite flag\n",
    "spark.sql(\"\"\"\n",
    "  SELECT *, CASE WHEN elite IS NOT NULL AND length(elite)>0 THEN 1 ELSE 0 END AS is_elite\n",
    "  FROM yelp_user\n",
    "\"\"\").createOrReplaceTempView(\"yelp_user_flag\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed48d0f-ca2b-4915-8596-74ee48cca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell F\n",
    "q1 = spark.sql(\"\"\"\n",
    "WITH r AS (\n",
    "  SELECT business_id, avg(stars) AS avg_star, count(*) AS n_reviews\n",
    "  FROM review GROUP BY business_id\n",
    ")\n",
    "SELECT bc.category,\n",
    "       round(avg(r.avg_star),3) AS avg_stars_across_biz,\n",
    "       sum(r.n_reviews) AS total_reviews,\n",
    "       count(*) AS n_businesses\n",
    "FROM r JOIN business_category bc ON r.business_id = bc.business_id\n",
    "GROUP BY bc.category\n",
    "HAVING sum(r.n_reviews) >= 300 AND count(*) >= 8\n",
    "ORDER BY avg_stars_across_biz DESC, total_reviews DESC\n",
    "\"\"\")\n",
    "q1.show(20, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4c701-f56f-4d28-9e50-581d798580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell G\n",
    "q2 = spark.sql(\"\"\"\n",
    "WITH rb AS (\n",
    "  SELECT r.user_id, b.city, b.state, r.stars\n",
    "  FROM review r JOIN business b ON r.business_id = b.business_id\n",
    ")\n",
    "SELECT rb.city, rb.state, u.is_elite,\n",
    "       count(*) AS n_reviews,\n",
    "       round(avg(stars),3) AS avg_stars,\n",
    "       round(stddev_pop(stars),3) AS sd_stars\n",
    "FROM rb JOIN yelp_user_flag u USING(user_id)\n",
    "GROUP BY rb.city, rb.state, u.is_elite\n",
    "HAVING count(*) >= 120\n",
    "ORDER BY rb.city, rb.state, u.is_elite DESC\n",
    "\"\"\")\n",
    "q2.show(20, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe73b63-4fd0-469c-90b0-080b40a48635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell H\n",
    "q3 = spark.sql(\"\"\"\n",
    "WITH agg AS (\n",
    "  SELECT business_id, avg(stars) AS avg_star, count(*) AS n_reviews\n",
    "  FROM review GROUP BY business_id\n",
    ")\n",
    "SELECT b.business_id, b.city, b.state, b.name,\n",
    "       ck.checkin_events, agg.avg_star, agg.n_reviews\n",
    "FROM agg\n",
    "JOIN checkin_counts ck USING(business_id)\n",
    "JOIN business b USING(business_id)\n",
    "WHERE agg.n_reviews >= 8 AND ck.checkin_events >= 1\n",
    "ORDER BY agg.n_reviews DESC\n",
    "\"\"\")\n",
    "q3.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769bebb-ebb8-4ba0-9b81-23525d1673e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell I\n",
    "q4 = spark.sql(\"\"\"\n",
    "WITH r AS (\n",
    "  SELECT business_id, avg(stars) AS avg_star, count(*) AS n_reviews\n",
    "  FROM review GROUP BY business_id\n",
    ")\n",
    "SELECT bc.category, b.is_open,\n",
    "       count(*) AS n_businesses,\n",
    "       round(avg(r.avg_star),3) AS avg_star_across_biz,\n",
    "       sum(r.n_reviews) AS total_reviews\n",
    "FROM business b\n",
    "JOIN r USING(business_id)\n",
    "JOIN business_category bc USING(business_id)\n",
    "GROUP BY bc.category, b.is_open\n",
    "HAVING sum(r.n_reviews) >= 300 AND count(*) >= 8\n",
    "ORDER BY bc.category, b.is_open DESC\n",
    "\"\"\")\n",
    "q4.show(20, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babcdd1-1d3f-4ca2-ae6a-d1201e22a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell J\n",
    "q1.limit(50).write.mode(\"overwrite\").parquet(\"/data/parquet/q1\")\n",
    "q2.limit(200).write.mode(\"overwrite\").parquet(\"/data/parquet/q2\")\n",
    "q3.limit(200).write.mode(\"overwrite\").parquet(\"/data/parquet/q3\")\n",
    "q4.limit(200).write.mode(\"overwrite\").parquet(\"/data/parquet/q4\")\n",
    "\n",
    "q1.limit(50).coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/data/csv/q1\")\n",
    "q2.limit(200).coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/data/csv/q2\")\n",
    "q3.limit(200).coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/data/csv/q3\")\n",
    "q4.limit(200).coalesce(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/data/csv/q4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3cd6e-1c40-43a5-a790-ce94f749222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: persist current results so we don't lose work on restart\n",
    "q1.write.mode(\"overwrite\").parquet(\"/data/parquet/_tmp_q1\")\n",
    "q2.write.mode(\"overwrite\").parquet(\"/data/parquet/_tmp_q2\")\n",
    "q3.write.mode(\"overwrite\").parquet(\"/data/parquet/_tmp_q3\")\n",
    "q4.write.mode(\"overwrite\").parquet(\"/data/parquet/_tmp_q4\")\n",
    "print(\"Saved q1..q4 to /data/parquet/_tmp_*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2a9da-3c41-4e41-8f40-03f0c123a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: write q1..q4 to Postgres\n",
    "jdbc = {\n",
    "    \"url\": \"jdbc:postgresql://db:5432/yelp\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"batchsize\": \"5000\",\n",
    "}\n",
    "\n",
    "for name, df in {\"q1\": q1, \"q2\": q2, \"q3\": q3, \"q4\": q4}.items():\n",
    "    (df.write.format(\"jdbc\")\n",
    "       .options(**jdbc)\n",
    "       .option(\"dbtable\", f\"public.{name}\")\n",
    "       .mode(\"overwrite\")\n",
    "       .save())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e859949-9ec1-4211-a724-56bb2f4b1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helpful indexes (safe to re-run)\n",
    "import os\n",
    "os.system(r\"\"\"\n",
    "docker exec -i yelp-db psql -U postgres -d yelp <<'SQL'\n",
    "CREATE INDEX IF NOT EXISTS idx_business_city_state ON business(city, state);\n",
    "CREATE INDEX IF NOT EXISTS idx_q1_cat        ON q1(category);\n",
    "CREATE INDEX IF NOT EXISTS idx_q2_city_state ON q2(city, state);\n",
    "CREATE INDEX IF NOT EXISTS idx_q3_biz        ON q3(business_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_q4_cat_open   ON q4(category, is_open);\n",
    "SQL\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
